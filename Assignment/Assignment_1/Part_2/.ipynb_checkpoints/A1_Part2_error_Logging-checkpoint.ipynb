{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "import os\n",
    "import string\n",
    "import glob\n",
    "import shutil\n",
    "import csv\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "from tempfile import NamedTemporaryFile\n",
    "from shutil import unpack_archive\n",
    "from io import BytesIO\n",
    "import logging\n",
    "from boto.s3.key import Key\n",
    "import ntpath\n",
    "import zipfile\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here I created handler, formatter, loglevel etc..\n",
    "ErrorLog = 'errorLoggingP2.log'\n",
    "log = logging.basicConfig(filename=ErrorLog,level=logging.DEBUG, format='%(asctime)s- %(levelname)s %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p', filemode = 'w')#ch1 = logging.FileHandler('ErrorLog') #output the logs to a file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory = os.path.dirname(os.getcwd()) \n",
    "path =  directory + '/Part_2'\n",
    "path\n",
    "\n",
    "year=''\n",
    "AWS_ACCESS_KEY_ID =''\n",
    "AWS_SECRET_ACCESS_KEY =''\n",
    "\n",
    "for i in range(1,len(sys.argv)):\n",
    "    val=sys.argv[i]\n",
    "    if val.startswith('year='):\n",
    "        pos=val.index(\"=\")\n",
    "        year=val[pos+1:len(val)]\n",
    "        continue\n",
    "    elif val.startswith('accessKey='):\n",
    "        pos=val.index(\"=\")\n",
    "        AWS_ACCESS_KEY_ID=val[pos+1:len(val)]\n",
    "        continue\n",
    "    elif val.startswith('secretKey='):\n",
    "        pos=val.index(\"=\")\n",
    "        AWS_SECRET_ACCESS_KEY=val[pos+1:len(val)]\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No access or secret key provided\n",
      "Invalid amazon keys\n"
     ]
    }
   ],
   "source": [
    "if not AWS_ACCESS_KEY_ID or not AWS_SECRET_ACCESS_KEY:\n",
    "    logging.warning('no access or secret key provided')\n",
    "    print('No access or secret key provided')\n",
    "    exit()\n",
    "try:\n",
    "    conn = boto.connect_s3(AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)\n",
    "    logging.info(\"Successfully connected to Amazon S3\")\n",
    "\n",
    "except:\n",
    "    logging.info(\"Invalid amazon keys\")\n",
    "    print(\"Invalid amazon keys\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the files in zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Unzip and downloading the files in the folder\n",
    "\n",
    "def openUnzip(url):\n",
    "    try:\n",
    "        with urlopen(url) as zipresp:\n",
    "            with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "                zfile.extractall(path+'/Log')\n",
    "        logging.info(\"url:\" + url + \" was opened successfully\")\n",
    "    except:\n",
    "        logging.warning(\"url:\" + url + \" was not correct. Check the inputted year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'info'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-8797e4a0401e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m      \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"year was left blank. Assigning the year 2005 automatically\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m      \u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"year was set properly\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mzipurl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mgeneralUrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"http://www.sec.gov/dera/data/PublicEDGAR-log-file-data/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'info'"
     ]
    }
   ],
   "source": [
    "#year = \n",
    "if(year is None):\n",
    "     logging.warning(\"year was left blank. Assigning the year 2005 automatically\")\n",
    "else:\n",
    "     logging.info(\"year was set properly\")\n",
    "zipurl = 'http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/'\n",
    "generalUrl = \"http://www.sec.gov/dera/data/PublicEDGAR-log-file-data/\"\n",
    "months = ['01',\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\"]\n",
    "for m in range(len(months)):\n",
    "    if(str(months[m]) is \"01\" or str(months[m]) is \"02\" or str(months[m]) is \"03\"):\n",
    "        urlAppended = zipurl + str(year) +\"/Qtr1/\"+\"log\"+str(year)+str(months[m])+\"01.zip\"\n",
    "        #print(urlAppended)\n",
    "        openUnzip(urlAppended)\n",
    "    if(str(months[m]) is \"04\" or str(months[m]) is \"05\" or str(months[m]) is \"06\"):\n",
    "        urlAppended = zipurl + str(year) +\"/Qtr2/\"+\"log\"+str(year)+str(months[m])+\"01.zip\"\n",
    "        #print(urlAppended)\n",
    "        #openUnzip(urlAppended)\n",
    "    if(str(months[m]) is \"07\" or str(months[m]) is \"08\" or str(months[m]) is \"09\"):\n",
    "        urlAppended = zipurl + str(year) +\"/Qtr3/\"+\"log\"+str(year)+str(months[m])+\"01.zip\"\n",
    "        #print(urlAppended)\n",
    "        #openUnzip(urlAppended)\n",
    "    if(str(months[m]) is \"10\" or str(months[m]) is \"11\" or str(months[m]) is \"12\"):\n",
    "        urlAppended = zipurl + str(year) +\"/Qtr4/\"+\"log\"+str(year)+str(months[m])+\"01.zip\"\n",
    "        #print(urlAppended)\n",
    "        #openUnzip(urlAppended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the CSV in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_log_files = glob.glob('/Users/sonalichaudhari/Desktop/FALL2017/ADS/Assignment_1/Part_2/Log/*.csv')\n",
    "dict_csv = {}\n",
    "for file_ in all_log_files:\n",
    "    f_name = os.path.basename(file_)\n",
    "    dict_csv[f_name] = pd.read_csv(file_,index_col=None, header=0)\n",
    "\n",
    "logging.info(\"Each csv has been read into a dataframe \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sonalichaudhari/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "#Extension\n",
    "a['extention'] = np.where(str(a['extention']).find('.') ==0,a['extention'],a['accession']+a['extention'])\n",
    "logging.info(\"replaced all extensions with no extension name in front of . with accession number\")\n",
    "\n",
    "#Zone\n",
    "df['zone'] = df['zone'].fillna(df['ip'].value_counts().idxmax())\n",
    "logging.info(\"replaced all zones with NAN with mazimum count of ip address\")\n",
    "\n",
    "#Browser\n",
    "df['browser'] = df['browser'].fillna(a['browser'].value_counts().idxmax())\n",
    "#browser is replaced with most used browser. chr stands for chromw\n",
    "df['browser'] = df['browser'].replace(np.nan, 'chr', regex=True)\n",
    "\n",
    "#IDX\n",
    "df['idx'] = df['idx'].fillna(a['idx'].value_counts().idxmax())\n",
    "logging.info(\"replaced all idx with NAN with value that max count\")\n",
    "\n",
    "#Norefer\n",
    "df['norefer'] = df['norefer'].fillna(df['norefer'].value_counts().idxmax())\n",
    "logging.info(\"replaced all norefer with NAN with value that max count\")\n",
    "\n",
    "#Noagent\n",
    "df['noagent'] = df['noagent'].fillna(df['noagent'].value_counts().idxmax())\n",
    "logging.info(\"replaced all noagent with NAN with value that max count\")\n",
    "\n",
    "#Crawler\n",
    "df['crawler'] = df['crawler'].fillna(df['crawler'].value_counts().idxmax())\n",
    "logging.info(\"replaced all crawler with NAN with value that max count\")\n",
    "\n",
    "#Replace size column which has NA with the mean\n",
    "df['size'] = df['size'].fillna(df['size'].mean(axis=0))\n",
    "\n",
    "df['date'].notnull().value\n",
    "#sub_df.iloc[0]['A']\n",
    "\n",
    "#Dropping Cik and accesion if NAN\n",
    "df.dropna(subset=['cik'])\n",
    "df.dropna(subset=['accession'])\n",
    "df.dropna(subset=['ip'])\n",
    "\n",
    "df.isnull().sum()\n",
    "df['ip'] = df['ip'].replace(np.nan, 'Unavailable', regex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SUMMARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sonalichaudhari/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "a['size_mean'] = a['size'].mean(axis=0)\n",
    "logging.info(\"replaced all size_mean with NAN with mean value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>zone</th>\n",
       "      <th>cik</th>\n",
       "      <th>accession</th>\n",
       "      <th>extention</th>\n",
       "      <th>code</th>\n",
       "      <th>size</th>\n",
       "      <th>idx</th>\n",
       "      <th>norefer</th>\n",
       "      <th>noagent</th>\n",
       "      <th>find</th>\n",
       "      <th>crawler</th>\n",
       "      <th>browser</th>\n",
       "      <th>size_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108.223.230.dda</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>740670.0</td>\n",
       "      <td>0000905608-00-000038</td>\n",
       "      <td>0000905608-00-000038.txt</td>\n",
       "      <td>200.0</td>\n",
       "      <td>4756.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5850.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151.151.7.agj</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91767.0</td>\n",
       "      <td>0001225208-13-025279</td>\n",
       "      <td>0001225208-13-025279.txt</td>\n",
       "      <td>200.0</td>\n",
       "      <td>5449.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5850.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151.151.7.agj</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91767.0</td>\n",
       "      <td>0001225208-13-025281</td>\n",
       "      <td>0001225208-13-025281.txt</td>\n",
       "      <td>200.0</td>\n",
       "      <td>5466.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5850.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.151.7.agj</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91767.0</td>\n",
       "      <td>0001225208-13-025278</td>\n",
       "      <td>0001225208-13-025278.txt</td>\n",
       "      <td>200.0</td>\n",
       "      <td>8012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5850.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.151.7.agj</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91767.0</td>\n",
       "      <td>0001225208-13-025280</td>\n",
       "      <td>0001225208-13-025280.txt</td>\n",
       "      <td>200.0</td>\n",
       "      <td>5568.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5850.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ip        date      time  zone       cik  \\\n",
       "0  108.223.230.dda  2014-01-01  00:00:00   0.0  740670.0   \n",
       "1    151.151.7.agj  2014-01-01  00:00:00   0.0   91767.0   \n",
       "2    151.151.7.agj  2014-01-01  00:00:00   0.0   91767.0   \n",
       "3    151.151.7.agj  2014-01-01  00:00:00   0.0   91767.0   \n",
       "4    151.151.7.agj  2014-01-01  00:00:00   0.0   91767.0   \n",
       "\n",
       "              accession                 extention   code    size  idx  \\\n",
       "0  0000905608-00-000038  0000905608-00-000038.txt  200.0  4756.0  0.0   \n",
       "1  0001225208-13-025279  0001225208-13-025279.txt  200.0  5449.0  0.0   \n",
       "2  0001225208-13-025281  0001225208-13-025281.txt  200.0  5466.0  0.0   \n",
       "3  0001225208-13-025278  0001225208-13-025278.txt  200.0  8012.0  0.0   \n",
       "4  0001225208-13-025280  0001225208-13-025280.txt  200.0  5568.0  0.0   \n",
       "\n",
       "   norefer  noagent  find  crawler  browser  size_mean  \n",
       "0      0.0      1.0  10.0      0.0      NaN     5850.2  \n",
       "1      0.0      1.0  10.0      0.0      NaN     5850.2  \n",
       "2      0.0      1.0  10.0      0.0      NaN     5850.2  \n",
       "3      0.0      1.0  10.0      0.0      NaN     5850.2  \n",
       "4      0.0      1.0  10.0      0.0      NaN     5850.2  "
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sonalichaudhari/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "a['ip_unique'] = a['ip'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sonalichaudhari/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>zone</th>\n",
       "      <th>cik</th>\n",
       "      <th>accession</th>\n",
       "      <th>extention</th>\n",
       "      <th>code</th>\n",
       "      <th>size</th>\n",
       "      <th>idx</th>\n",
       "      <th>norefer</th>\n",
       "      <th>noagent</th>\n",
       "      <th>find</th>\n",
       "      <th>crawler</th>\n",
       "      <th>browser</th>\n",
       "      <th>size_mean</th>\n",
       "      <th>ip_unique</th>\n",
       "      <th>abc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108.223.230.dda</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>740670.0</td>\n",
       "      <td>0000905608-00-000038</td>\n",
       "      <td>0000905608-00-000038.txt</td>\n",
       "      <td>200.0</td>\n",
       "      <td>4756.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5850.2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151.151.7.agj</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91767.0</td>\n",
       "      <td>0001225208-13-025279</td>\n",
       "      <td>0001225208-13-025279.txt</td>\n",
       "      <td>200.0</td>\n",
       "      <td>5449.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5850.2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151.151.7.agj</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91767.0</td>\n",
       "      <td>0001225208-13-025281</td>\n",
       "      <td>0001225208-13-025281.txt</td>\n",
       "      <td>200.0</td>\n",
       "      <td>5466.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5850.2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151.151.7.agj</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91767.0</td>\n",
       "      <td>0001225208-13-025278</td>\n",
       "      <td>0001225208-13-025278.txt</td>\n",
       "      <td>200.0</td>\n",
       "      <td>8012.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5850.2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.151.7.agj</td>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91767.0</td>\n",
       "      <td>0001225208-13-025280</td>\n",
       "      <td>0001225208-13-025280.txt</td>\n",
       "      <td>200.0</td>\n",
       "      <td>5568.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5850.2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ip        date      time  zone       cik  \\\n",
       "0  108.223.230.dda  2014-01-01  00:00:00   0.0  740670.0   \n",
       "1    151.151.7.agj  2014-01-01  00:00:00   0.0   91767.0   \n",
       "2    151.151.7.agj  2014-01-01  00:00:00   0.0   91767.0   \n",
       "3    151.151.7.agj  2014-01-01  00:00:00   0.0   91767.0   \n",
       "4    151.151.7.agj  2014-01-01  00:00:00   0.0   91767.0   \n",
       "\n",
       "              accession                 extention   code    size  idx  \\\n",
       "0  0000905608-00-000038  0000905608-00-000038.txt  200.0  4756.0  0.0   \n",
       "1  0001225208-13-025279  0001225208-13-025279.txt  200.0  5449.0  0.0   \n",
       "2  0001225208-13-025281  0001225208-13-025281.txt  200.0  5466.0  0.0   \n",
       "3  0001225208-13-025278  0001225208-13-025278.txt  200.0  8012.0  0.0   \n",
       "4  0001225208-13-025280  0001225208-13-025280.txt  200.0  5568.0  0.0   \n",
       "\n",
       "   norefer  noagent  find  crawler  browser  size_mean  ip_unique  abc  \n",
       "0      0.0      1.0  10.0      0.0      NaN     5850.2          2  NaN  \n",
       "1      0.0      1.0  10.0      0.0      NaN     5850.2          2  NaN  \n",
       "2      0.0      1.0  10.0      0.0      NaN     5850.2          2  NaN  \n",
       "3      0.0      1.0  10.0      0.0      NaN     5850.2          2  NaN  \n",
       "4      0.0      1.0  10.0      0.0      NaN     5850.2          2  NaN  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['abc'] = a['cik'].value_counts()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-271374a73826>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "a.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zipping the CSVs and the summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zipping(directory):\n",
    " \n",
    "    # initializing empty file paths list\n",
    "    file_paths = []\n",
    " \n",
    "    # crawling through directory and subdirectories\n",
    "    for root, directories, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.csv'):\n",
    "                filepath = os.path.join(root, filename)\n",
    "                file_paths.append(filepath)\n",
    "                \n",
    "                with ZipFile('LogFiles.zip','w') as zip:\n",
    "                    for file in file_paths:\n",
    "                        print(file)\n",
    "                        zip.write(file)\n",
    " \n",
    "            print('All files zipped successfully!')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def zipdir(path, ziph):\n",
    "    #for root, directories, files in os.walk(path):\n",
    "    #print(files)\n",
    "    ziph.write(os.path.join('log20040101.csv'))\n",
    "#    ziph.write(os.path.join('master_df_summary.csv'))\n",
    "    ziph.write(os.path.join('problem2_log.log'))   \n",
    "\n",
    "logfile = zipfile.ZipFile('LogFile.zip', 'w', zipfile.ZIP_DEFLATED)\n",
    "zipdir(curp,logfile)\n",
    "zipf.close()\n",
    "logging.info('Compiled csv and log file zipped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:   \n",
    "    bucket_name = AWS_ACCESS_KEY_ID.lower()+str(st).replace(\" \", \"\").replace(\"-\", \"\").replace(\":\",\"\").replace(\".\",\"\")\n",
    "    bucket = conn.create_bucket(bucket_name,  location=s3.connection.Location.DEFAULT)\n",
    "    #zipfile = 'Problem1.zip'\n",
    "    logging.info(\"Uploading to Amazon S3\", zipfile, bucket_name)\n",
    "    \n",
    "    def percent_cb(complete, total):\n",
    "        sys.stdout.write('.')\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    k = Key(bucket)\n",
    "    k.key = 'Assign1Problem1'\n",
    "    k.set_contents_from_filename(zipfile,\n",
    "        cb=percent_cb, num_cb=10)\n",
    "    logging.into(\"Zip File successfully uploaded to S3\")\n",
    "except:\n",
    "    logging.info(\"invalid amazon keys\")\n",
    "    print(\"invalid amazon keys\")\n",
    "    exit()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
