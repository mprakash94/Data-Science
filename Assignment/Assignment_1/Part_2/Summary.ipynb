{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import urllib.request\n",
    "#from urllib.request import urlopen\n",
    "import urllib\n",
    "import os\n",
    "import string\n",
    "import glob\n",
    "import shutil\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from zipfile import ZipFile\n",
    "from tempfile import NamedTemporaryFile\n",
    "from shutil import unpack_archive\n",
    "from io import BytesIO\n",
    "import logging\n",
    "from boto.s3.key import Key\n",
    "import ntpath\n",
    "import zipfile\n",
    "import sys\n",
    "from os.path import basename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here I created handler, formatter, loglevel etc..\n",
    "ErrorLog = 'errorLoggingP2.log'\n",
    "log = logging.basicConfig(filename=ErrorLog,level=logging.DEBUG, format='%(asctime)s- %(levelname)s %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p', filemode = 'w')#ch1 = logging.FileHandler('ErrorLog') #output the logs to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "directory = os.path.dirname(os.getcwd()) \n",
    "cur_path =  directory + '/Part_2'\n",
    "newpath = '/Users/sonalichaudhari/Desktop/FALL2017/ADS/Assignment_1/Part_2/LogCSV'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "year='2004'\n",
    "AWS_ACCESS_KEY_ID =''\n",
    "AWS_SECRET_ACCESS_KEY =''\n",
    "\n",
    "for i in range(1,len(sys.argv)):\n",
    "    val=sys.argv[i]\n",
    "    if val.startswith('year='):\n",
    "        pos=val.index(\"=\")\n",
    "        year=val[pos+1:len(val)]\n",
    "        continue\n",
    "    elif val.startswith('accessKey='):\n",
    "        pos=val.index(\"=\")\n",
    "        AWS_ACCESS_KEY_ID=val[pos+1:len(val)]\n",
    "        continue\n",
    "    elif val.startswith('secretKey='):\n",
    "        pos=val.index(\"=\")\n",
    "        AWS_SECRET_ACCESS_KEY=val[pos+1:len(val)]\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No access or secret key provided\n",
      "Invalid amazon keys\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "if not AWS_ACCESS_KEY_ID or not AWS_SECRET_ACCESS_KEY:\n",
    "    logging.warning('no access or secret key provided')\n",
    "    print('No access or secret key provided')\n",
    "    #exit()\n",
    "try:\n",
    "    conn = boto.connect_s3(AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY)\n",
    "    logging.info(\"Successfully connected to Amazon S3\")\n",
    "\n",
    "except:\n",
    "    logging.info(\"Invalid amazon keys\")\n",
    "    print(\"Invalid amazon keys\")\n",
    "    #exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the files in zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Unzip and downloading the files in the folder\n",
    "\n",
    "def openUnzip(url):\n",
    "    try:\n",
    "        if not os.path.exists(newpath):\n",
    "            os.makedirs(newpath)\n",
    "            with urlopen(url) as zipresp:\n",
    "                with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "                    zfile.extractall(newpath)\n",
    "        else:\n",
    "            with urlopen(url) as zipresp:\n",
    "                with ZipFile(BytesIO(zipresp.read())) as zfile:\n",
    "                    zfile.extractall(newpath)\n",
    "    except:\n",
    "        logging.warning(\"url:\" + url + \" was not correct. Check the inputted year\")         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#year = \n",
    "if(year is None):\n",
    "     logging.warning(\"year was left blank. Assigning the year 2005 automatically\")\n",
    "else:\n",
    "     logging.info(\"year was set properly\")\n",
    "zipurl = 'http://www.sec.gov/dera/data/Public-EDGAR-log-file-data/'\n",
    "generalUrl = \"http://www.sec.gov/dera/data/PublicEDGAR-log-file-data/\"\n",
    "months = ['01',\"02\",\"03\",\"04\",\"05\",\"06\",\"07\",\"08\",\"09\",\"10\",\"11\",\"12\"]\n",
    "for m in range(len(months)):\n",
    "    if(str(months[m]) is \"01\" or str(months[m]) is \"02\" or str(months[m]) is \"03\"):\n",
    "        urlAppended = zipurl + str(year) +\"/Qtr1/\"+\"log\"+str(year)+str(months[m])+\"01.zip\"\n",
    "        #print(urlAppended)\n",
    "        openUnzip(urlAppended)\n",
    "    if(str(months[m]) is \"04\" or str(months[m]) is \"05\" or str(months[m]) is \"06\"):\n",
    "        urlAppended = zipurl + str(year) +\"/Qtr2/\"+\"log\"+str(year)+str(months[m])+\"01.zip\"\n",
    "        #print(urlAppended)\n",
    "        openUnzip(urlAppended)\n",
    "    if(str(months[m]) is \"07\" or str(months[m]) is \"08\" or str(months[m]) is \"09\"):\n",
    "        urlAppended = zipurl + str(year) +\"/Qtr3/\"+\"log\"+str(year)+str(months[m])+\"01.zip\"\n",
    "        #print(urlAppended)\n",
    "        openUnzip(urlAppended)\n",
    "    if(str(months[m]) is \"10\" or str(months[m]) is \"11\" or str(months[m]) is \"12\"):\n",
    "        urlAppended = zipurl + str(year) +\"/Qtr4/\"+\"log\"+str(year)+str(months[m])+\"01.zip\"\n",
    "        #print(urlAppended)\n",
    "        openUnzip(urlAppended)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the CSV in a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading all CSVs and storing it in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_log_files = glob.glob(newpath+'/*.csv')\n",
    "dict_csv = {}\n",
    "for file_ in all_log_files:\n",
    "    f_name = os.path.basename(file_)\n",
    "    dict_csv[f_name] = pd.read_csv(file_,index_col=None, header=0)\n",
    "\n",
    "logging.info(\"Each csv has been read into a dataframe \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dict_csv.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key,value in dict_csv.items():\n",
    "    df = dict_csv[key]\n",
    "    \n",
    "    #Dropping Cik,ip and accesion if NAN\n",
    "    df.dropna(subset=['cik'])\n",
    "    df.dropna(subset=['accession'])\n",
    "    df.dropna(subset=['ip'])\n",
    "    \n",
    "    # df.isnull().sum()\n",
    "\n",
    "    #Extension : if only extension is there, appending accession before the extension\n",
    "    df['extention'] = np.where(str(df['extention']).find('.') ==0,df['extention'],df['accession']+df['extention'])\n",
    "    logging.info(\"replaced all extensions with no extension name in front of . with accession number\")\n",
    "    df['extention'] = df['extention'].replace(np.nan, 'Unavailable', regex=True)\n",
    "    logging.info(\"replaced all extensions with NAN by 'Unavailable'\")\n",
    "\n",
    "    #Zone : if NAN fill it with the max used zone value\n",
    "    df['zone'] = df['zone'].fillna(df['ip'].value_counts().idxmax())\n",
    "    logging.info(\"replaced all zones with NAN with mazimum count of ip address\")\n",
    "    \n",
    "    #IDX : if NAN fill it with the max used idx value\n",
    "    df['idx'] = df['idx'].fillna(df['idx'].value_counts().idxmax())\n",
    "    logging.info(\"replaced all idx with NAN with value that max count\")\n",
    "    \n",
    "    #Norefer : if NAN fill it with the max used norefer value\n",
    "    df['norefer'] = df['norefer'].fillna(df['norefer'].value_counts().idxmax())\n",
    "    logging.info(\"replaced all norefer with NAN with value that max count\")\n",
    "\n",
    "    #Noagent : if NAN fill it with the max used noagent value\n",
    "    df['noagent'] = df['noagent'].fillna(df['noagent'].value_counts().idxmax())\n",
    "    logging.info(\"replaced all noagent with NAN with value that max count\")\n",
    "\n",
    "    #Crawler : if NAN fill it with the max used crawler value\n",
    "    df['crawler'] = df['crawler'].fillna(df['crawler'].value_counts().idxmax())\n",
    "    logging.info(\"replaced all crawler with NAN with value that max count\")\n",
    "\n",
    "    #Replace size column which has NAN with the mean file size\n",
    "    df['size'] = df['size'].fillna(df['size'].mean(axis=0))\n",
    "\n",
    "    # df['date'].notnull().value\n",
    "    # #sub_df.iloc[0]['A']\n",
    "\n",
    "    #Browser : if NAN fill it with the max used browswe value\n",
    "    df['browser'] = df['browser'].fillna(df['browser'].value_counts().idxmax())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Mean File size\n",
    "#df['size_mean'] = df['size'].mean(axis=0)\n",
    "# Unique IPs in the given month\n",
    "#df['ip_unique'] = df['ip'].nunique()\n",
    "#df.describe()\n",
    "#Unique CIK\n",
    "#df['cik'].nunique()\n",
    "#Unique Accession Number\n",
    "#df['accession'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concating all the dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdf = pd.concat(dict_csv)\n",
    "mdf.to_csv(newpath+'Combined_CSV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>ip</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>zone</th>\n",
       "      <th>cik</th>\n",
       "      <th>accession</th>\n",
       "      <th>extention</th>\n",
       "      <th>code</th>\n",
       "      <th>size</th>\n",
       "      <th>idx</th>\n",
       "      <th>norefer</th>\n",
       "      <th>noagent</th>\n",
       "      <th>find</th>\n",
       "      <th>crawler</th>\n",
       "      <th>browser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">log20040101.csv</th>\n",
       "      <th>0</th>\n",
       "      <td>24.70.95.bjg</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>500.0</td>\n",
       "      <td>771252.0</td>\n",
       "      <td>0001047469-03-042434</td>\n",
       "      <td>0001047469-03-042434a2125426zs-3.htm</td>\n",
       "      <td>200.0</td>\n",
       "      <td>123558.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>64.165.202.fca</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>500.0</td>\n",
       "      <td>849778.0</td>\n",
       "      <td>0000927016-03-001282</td>\n",
       "      <td>0000927016-03-001282dex1014.txt</td>\n",
       "      <td>200.0</td>\n",
       "      <td>38688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>207.168.174.jdd</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>00:00:01</td>\n",
       "      <td>500.0</td>\n",
       "      <td>1244190.0</td>\n",
       "      <td>0001244190-03-000001</td>\n",
       "      <td>0001244190-03-000001edgar.xml</td>\n",
       "      <td>200.0</td>\n",
       "      <td>5683.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>64.165.202.fca</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>00:00:02</td>\n",
       "      <td>500.0</td>\n",
       "      <td>849778.0</td>\n",
       "      <td>0000927016-03-001282</td>\n",
       "      <td>0000927016-03-001282dex1015.txt</td>\n",
       "      <td>200.0</td>\n",
       "      <td>17038.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>64.165.202.fca</td>\n",
       "      <td>2004-01-01</td>\n",
       "      <td>00:00:03</td>\n",
       "      <td>500.0</td>\n",
       "      <td>849778.0</td>\n",
       "      <td>0000927016-03-001282</td>\n",
       "      <td>0000927016-03-001282dex211.htm</td>\n",
       "      <td>200.0</td>\n",
       "      <td>9025.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                ip        date      time   zone        cik  \\\n",
       "log20040101.csv 0     24.70.95.bjg  2004-01-01  00:00:00  500.0   771252.0   \n",
       "                1   64.165.202.fca  2004-01-01  00:00:00  500.0   849778.0   \n",
       "                2  207.168.174.jdd  2004-01-01  00:00:01  500.0  1244190.0   \n",
       "                3   64.165.202.fca  2004-01-01  00:00:02  500.0   849778.0   \n",
       "                4   64.165.202.fca  2004-01-01  00:00:03  500.0   849778.0   \n",
       "\n",
       "                              accession                             extention  \\\n",
       "log20040101.csv 0  0001047469-03-042434  0001047469-03-042434a2125426zs-3.htm   \n",
       "                1  0000927016-03-001282       0000927016-03-001282dex1014.txt   \n",
       "                2  0001244190-03-000001         0001244190-03-000001edgar.xml   \n",
       "                3  0000927016-03-001282       0000927016-03-001282dex1015.txt   \n",
       "                4  0000927016-03-001282        0000927016-03-001282dex211.htm   \n",
       "\n",
       "                    code      size  idx  norefer  noagent  find  crawler  \\\n",
       "log20040101.csv 0  200.0  123558.0  0.0      0.0      0.0  10.0      0.0   \n",
       "                1  200.0   38688.0  0.0      1.0      0.0   0.0      0.0   \n",
       "                2  200.0    5683.0  0.0      1.0      1.0   0.0      0.0   \n",
       "                3  200.0   17038.0  0.0      1.0      0.0   0.0      0.0   \n",
       "                4  200.0    9025.0  0.0      1.0      0.0   0.0      0.0   \n",
       "\n",
       "                  browser  \n",
       "log20040101.csv 0     win  \n",
       "                1     win  \n",
       "                2     win  \n",
       "                3     win  \n",
       "                4     win  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = mdf.head(20)\n",
    "a.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#kk = mdf['cik'].value_counts(sort=True, ascending=False,)\n",
    "cik_ = a.groupby(['cik']).size().nlargest(10)\n",
    "#cik_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdf['ip'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a['Quarter']= a['date'][0][5:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for r,i in a.iterrows():\n",
    "    month = a['date'][r][5:7]\n",
    "    x = int(month)\n",
    "    if x < 4:\n",
    "        a['Quarter'] = 'QTR1'\n",
    "    elif (x > 3) and (x < 7):\n",
    "        a[\"Quarter\"] = 'QTR2'\n",
    "    elif x >7 and x < 10:\n",
    "        a['Quarter'] = 'QTR3'\n",
    "    else:\n",
    "        a['Quarter'] = 'QTR4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
