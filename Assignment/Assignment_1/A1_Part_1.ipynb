{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lxml.html import parse\n",
    "from urllib.request import urlopen\n",
    "from pandas.io.parsers import TextParser\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup #for web scraping\n",
    "import csv  \n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from pandas.io.parsers import TextParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the cik and acc number in variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ErrorLog = 'errorLogging.log'\n",
    "logging.basicConfig(filename=ErrorLog,level=logging.DEBUG, filemode = 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_obj = open(\"cikInformation.txt\",\"r\" )\n",
    "cik = file_obj.readline().rstrip()\n",
    "acc = file_obj.readline().rstrip()\n",
    "if((cik is None or cik is \"\") or (acc is None or acc is \"\")):\n",
    "    logging.info(\"Cik or access number was left blank. Assigning a IBM's CIK and access key automatically\")\n",
    "    cik = \"51143\"\n",
    "    acc = \"0000051143-13-000007\"\n",
    "    accNoDash = acc.replace('-', '')\n",
    "else:\n",
    "    accNoDash = acc.replace('-', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51143\n",
      "000005114313000007\n"
     ]
    }
   ],
   "source": [
    "print(cik)\n",
    "print(accNoDash)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Checking if log works: logging.debug('This message should go to the log file')\n",
    "\n",
    "try:\n",
    "    url = 'https://www.sec.gov/Archives/edgar/data/'+cik+'/'+accNoDash+'/'+acc+'-index.htm'\n",
    "    parsed = parse(urlopen(url))\n",
    "    doc = parsed.getroot()\n",
    "except:\n",
    "    logging.critical(\"Invalid company's url\")\n",
    "    logging.info(\"Validate that cik number and acces number are correctly inputted\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "url = 'https://www.sec.gov/Archives/edgar/data/'+cik+'/'+accNoDash+'/'+acc+'-index.htm'\n",
    "parsed = parse(urlopen(url))\n",
    "doc = parsed.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#links = doc.findall('.//a')\n",
    "#url = [lnk.get('href')for lnk in doc.findall('.//a')]\n",
    "#url[10:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tables = doc.findall('.//table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Doc=[]\n",
    "for t in range(len(tables)):\n",
    "    example = tables[t]\n",
    "    \n",
    "    rows = example.findall('.//tr')\n",
    "    \n",
    "    def _unpack(row, kind='td'):\n",
    "        elts = row.findall('.//%s' % kind)\n",
    "        return [val.text_content() for val in elts]\n",
    "\n",
    "    def parse_options_data(table):\n",
    "        rows=table.findall('.//tr')\n",
    "        header = _unpack(rows[0], kind ='th')\n",
    "        data = [_unpack(r) for r in rows[1:]]\n",
    "        return TextParser(data, names = header).get_chunk()\n",
    "\n",
    "    example_data = parse_options_data(example)\n",
    "    \n",
    "    \n",
    "    for r in range(len(example_data)):\n",
    "        d= example_data['Description'][r]\n",
    "        if d =='10-Q' :\n",
    "            Doc.append(example_data['Document'][r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ibm13q3_10q.htm']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "https://www.sec.gov/Archives/edgar/data/51143/000005114313000007/ibm13q3_10q.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-Q Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for link in Doc:\n",
    "    try:\n",
    "        L=[] #For storing all the 10-Q file links\n",
    "        l = 'https://www.sec.gov/Archives/edgar/data/'+cik+'/'+accNoDash+'/'+link+''\n",
    "        L.append(l)\n",
    "    except:\n",
    "        logging.critical(\"Invalid 10Q url\")\n",
    "        logging.info(\"Validate that cik number and acces number are correctly inputted\")\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.sec.gov/Archives/edgar/data/51143/000005114313000007/ibm13q3_10q.htm']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traversing each 10-Q links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for l in L:\n",
    "    #p = parse(urlopen(l))\n",
    "    #q_link= p.getroot()\n",
    "    #tables_2 = q_link.findall('.//table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traversing through all tables in 10-Q document and storing the tables in the list -> f_tables[ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for l in L:\n",
    "    page = urllib.request.urlopen(l)\n",
    "    soup = BeautifulSoup(page,\"lxml\")\n",
    "    # Grabing all the tables considering the table tags\n",
    "    table_2 = soup.select('div table')\n",
    "        \n",
    "    f_tables=[]\n",
    "        \n",
    "    for t in table_2:\n",
    "        for row in t.find_all('tr'):\n",
    "            for cell in row.findAll('td') :\n",
    "                flag = 0\n",
    "                if ('$' in cell.get_text().strip() or '%' in cell.get_text().strip()):\n",
    "                    f_tables.append(t)\n",
    "                    flag=1\n",
    "                    break\n",
    "            if(flag==1):\n",
    "                break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# n_columns = 0\n",
    "# n_rows=0\n",
    "# column_names = []\n",
    "    \n",
    "\n",
    "# for row in f_tables[4].find_all('tr'):\n",
    "#             td_tags = row.find_all('td')\n",
    "#             print(len(td_tags))\n",
    "#             if len(td_tags) > 0:\n",
    "#                 n_rows+=1\n",
    "#                 if n_columns == 0:\n",
    "#                         # Set the number of columns for our table\n",
    "#                     n_columns = len(td_tags)\n",
    "        \n",
    "#         # Handle column names if we find them\n",
    "#             th_tags = row.find_all('th') \n",
    "#             if len(th_tags) > 0 and len(column_names) == 0:\n",
    "#                 for th in th_tags:\n",
    "#                     column_names.append(th.get_text())\n",
    "        \n",
    "# if len(column_names) > 0 and len(column_names) != n_columns:\n",
    "#                     raise Exception(\"Column titles do not match the number of columns\")\n",
    "    \n",
    "# columns = column_names if len(column_names) > 0 else range(0,n_columns)\n",
    "# df = pd.DataFrame(columns = columns,index= range(0,n_rows))\n",
    "\n",
    "# row_marker = 0\n",
    "# for row in f_tables[4].find_all('tr'):\n",
    "#     column_marker = 0\n",
    "#     columns = row.find_all('td')\n",
    "#     for column in columns:\n",
    "#         df.iat[row_marker,column_marker] = column.get_text()\n",
    "#         column_marker += 1\n",
    "#     if len(columns) > 0:\n",
    "#         row_marker += 1\n",
    "        \n",
    "# for col in df:\n",
    "#     try:\n",
    "#         df[col] = df[col].astype(float)\n",
    "#     except ValueError:\n",
    "#         pass\n",
    "\n",
    "# #Removing unnecessary blanks\n",
    "# #df.replace('\\n\\xa0\\n', '')\n",
    "# for i in range(n_columns):\n",
    "#     for j in range(n_rows):\n",
    "#         if(type(df[i][j]) != float):\n",
    "#             x = df[i][j]\n",
    "#             df[i][j] = x.strip('\\n')\n",
    "#         else:\n",
    "#             x = str(df[i][j])\n",
    "#             df[i][j] = x.strip('\\n')\n",
    "\n",
    "# # Converting the dataframe in csv file\n",
    "\n",
    "# with open('1.csv', 'a') as csvfile:\n",
    "#     df.to_csv(csvfile, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the table in a CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for tt in f_tables:\n",
    "    records = []\n",
    "    for tr in tt.find_all('tr'):\n",
    "        rowString=[]\n",
    "        for td in tr.findAll('td'):\n",
    "            p = td.find_all('p')\n",
    "            if len(p)>0:\n",
    "                for ps in p:\n",
    "                    ps_text = ps.get_text().replace(\"\\n\",\" \") \n",
    "                    ps_text = ps_text.replace(\"\\xa0\",\"\")                 \n",
    "                    rowString.append(ps_text)\n",
    "            else:\n",
    "                td_text=td.get_text().replace(\"\\n\",\" \")\n",
    "                td_text = td_text.replace(\"\\xa0\",\"\")\n",
    "                rowString.append(td_text)\n",
    "        records.append(rowString)        \n",
    "    with open((str(f_tables.index(tt)+1)+'_'+str(cik)+'.csv'), 'w')as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(records)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
