{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml.html import parse\n",
    "from urllib.request import urlopen\n",
    "from pandas.io.parsers import TextParser\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup #for web scraping\n",
    "import csv  \n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "from boto.s3.key import Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the cik and acc number in variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I created handler, formatter, loglevel etc..\n",
    "ErrorLog = 'errorLoggingP1.log'\n",
    "log = logging.basicConfig(filename=ErrorLog,level=logging.DEBUG, format='%(asctime)s- %(levelname)s %(message)s', datefmt='%m/%d/%Y %I:%M:%S %p', filemode = 'w')#ch1 = logging.FileHandler('ErrorLog') #output the logs to a file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Read from Console\n",
    "argLen=len(sys.argv)\n",
    "cik=''\n",
    "acc=''\n",
    "AWS_ACCESS_KEY_ID=''\n",
    "AWS_SECRET_ACCESS_KEY=''\n",
    "\n",
    "for i in range(1,argLen):\n",
    "    val=sys.argv[i]\n",
    "    if val.startswith('cik='):\n",
    "        pos=val.index(\"=\")\n",
    "        cik=val[pos+1:len(val)]\n",
    "        continue\n",
    "    elif val.startswith('accessionNumber='):\n",
    "        pos=val.index(\"=\")\n",
    "        acc=val[pos+1:len(val)]\n",
    "        continue\n",
    "    elif val.startswith('accessKey='):\n",
    "        pos=val.index(\"=\")\n",
    "        accessKey=val[pos+1:len(val)]\n",
    "        continue\n",
    "    elif val.startswith('secretKey='):\n",
    "        pos=val.index(\"=\")\n",
    "        AWS_ACCESS_KEY_ID=val[pos+1:len(val)]\n",
    "        continue\n",
    "    elif val.startswith('location='):\n",
    "        pos=val.index(\"=\")\n",
    "        AWS_SECRET_ACCESS_KEY=val[pos+1:len(val)]\n",
    "        continue\n",
    "\n",
    "if((cik is None or cik is \"\") or (acc is None or acc is \"\")):\n",
    "    logging.info(\"Cik or access number was left blank. Assigning a IBM's CIK and access key automatically\")\n",
    "    print(\"Cik or access number was left blank. Assigning a IBM's CIK and access key automatically\")\n",
    "    cik = \"51143\"\n",
    "    acc = \"0000051143-13-000007\"\n",
    "    accNoDash = acc.replace('-', '')\n",
    "else:\n",
    "    accNoDash = acc.replace('-', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51143\n",
      "000005114313000007\n"
     ]
    }
   ],
   "source": [
    "print(cik)\n",
    "print(accNoDash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    connnnect = boto.connect_s3(AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY)\n",
    "\n",
    "    logging.info(\"Successfully connected to Amazon S3\")\n",
    "\n",
    "except:\n",
    "    logging.warning(\"incorrect aws access key and/or secret key\")\n",
    "    print(\"incorrect aws access key and/or secret key\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the url "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Checking if log works: logging.debug('This message should go to the log file')\n",
    "\n",
    "try:\n",
    "    url = 'https://www.sec.gov/Archives/edgar/data/'+cik+'/'+accNoDash+'/'+acc+'-index.htm'\n",
    "    parsed = parse(urlopen(url))\n",
    "    doc = parsed.getroot()\n",
    "except:\n",
    "    logging.critical(\"Invalid company's url\")\n",
    "    logging.info(\"Validate that cik number and acces number are correctly inputted\")\n",
    "    print(\"Invalid company's url. Validate accession number and cik number\")\n",
    "    exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.sec.gov/Archives/edgar/data/'+cik+'/'+accNoDash+'/'+acc+'-index.htm'\n",
    "parsed = parse(urlopen(url))\n",
    "doc = parsed.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#links = doc.findall('.//a')\n",
    "#url = [lnk.get('href')for lnk in doc.findall('.//a')]\n",
    "#url[10:23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tables = doc.findall('.//table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Doc=[]\n",
    "for t in range(len(tables)):\n",
    "    example = tables[t]\n",
    "    \n",
    "    rows = example.findall('.//tr')\n",
    "    \n",
    "    def _unpack(row, kind='td'):\n",
    "        elts = row.findall('.//%s' % kind)\n",
    "        return [val.text_content() for val in elts]\n",
    "\n",
    "    def parse_options_data(table):\n",
    "        rows=table.findall('.//tr')\n",
    "        header = _unpack(rows[0], kind ='th')\n",
    "        data = [_unpack(r) for r in rows[1:]]\n",
    "        return TextParser(data, names = header).get_chunk()\n",
    "\n",
    "    example_data = parse_options_data(example)\n",
    "    \n",
    "    \n",
    "    for r in range(len(example_data)):\n",
    "        d= example_data['Description'][r]\n",
    "        if d =='10-Q' :\n",
    "            Doc.append(example_data['Document'][r])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ibm13q3_10q.htm']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "https://www.sec.gov/Archives/edgar/data/51143/000005114313000007/ibm13q3_10q.htm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-Q Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for link in Doc:\n",
    "    try:\n",
    "        L=[] #For storing all the 10-Q file links\n",
    "        l = 'https://www.sec.gov/Archives/edgar/data/'+cik+'/'+accNoDash+'/'+link+''\n",
    "        L.append(l)\n",
    "    except:\n",
    "        logging.critical(\"Invalid 10Q url\")\n",
    "        logging.info(\"Validate that cik number and acces number are correctly inputted\")\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.sec.gov/Archives/edgar/data/51143/000005114313000007/ibm13q3_10q.htm']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traversing each 10-Q links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for l in L:\n",
    "    #p = parse(urlopen(l))\n",
    "    #q_link= p.getroot()\n",
    "    #tables_2 = q_link.findall('.//table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traversing through all tables in 10-Q document and storing the tables in the list -> f_tables[ ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for l in L:\n",
    "    page = urllib.request.urlopen(l)\n",
    "    soup = BeautifulSoup(page,\"lxml\")\n",
    "    # Grabing all the tables considering the table tags\n",
    "    table_2 = soup.select('div table')\n",
    "        \n",
    "    f_tables=[]\n",
    "        \n",
    "    for t in table_2:\n",
    "        for row in t.find_all('tr'):\n",
    "            for cell in row.findAll('td') :\n",
    "                flag = 0\n",
    "                if ('$' in cell.get_text().strip() or '%' in cell.get_text().strip()):\n",
    "                    f_tables.append(t)\n",
    "                    flag=1\n",
    "                    break\n",
    "            if(flag==1):\n",
    "                break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_columns = 0\n",
    "# n_rows=0\n",
    "# column_names = []\n",
    "    \n",
    "\n",
    "# for row in f_tables[4].find_all('tr'):\n",
    "#             td_tags = row.find_all('td')\n",
    "#             print(len(td_tags))\n",
    "#             if len(td_tags) > 0:\n",
    "#                 n_rows+=1\n",
    "#                 if n_columns == 0:\n",
    "#                         # Set the number of columns for our table\n",
    "#                     n_columns = len(td_tags)\n",
    "        \n",
    "#         # Handle column names if we find them\n",
    "#             th_tags = row.find_all('th') \n",
    "#             if len(th_tags) > 0 and len(column_names) == 0:\n",
    "#                 for th in th_tags:\n",
    "#                     column_names.append(th.get_text())\n",
    "        \n",
    "# if len(column_names) > 0 and len(column_names) != n_columns:\n",
    "#                     raise Exception(\"Column titles do not match the number of columns\")\n",
    "    \n",
    "# columns = column_names if len(column_names) > 0 else range(0,n_columns)\n",
    "# df = pd.DataFrame(columns = columns,index= range(0,n_rows))\n",
    "\n",
    "# row_marker = 0\n",
    "# for row in f_tables[4].find_all('tr'):\n",
    "#     column_marker = 0\n",
    "#     columns = row.find_all('td')\n",
    "#     for column in columns:\n",
    "#         df.iat[row_marker,column_marker] = column.get_text()\n",
    "#         column_marker += 1\n",
    "#     if len(columns) > 0:\n",
    "#         row_marker += 1\n",
    "        \n",
    "# for col in df:\n",
    "#     try:\n",
    "#         df[col] = df[col].astype(float)\n",
    "#     except ValueError:\n",
    "#         pass\n",
    "\n",
    "# #Removing unnecessary blanks\n",
    "# #df.replace('\\n\\xa0\\n', '')\n",
    "# for i in range(n_columns):\n",
    "#     for j in range(n_rows):\n",
    "#         if(type(df[i][j]) != float):\n",
    "#             x = df[i][j]\n",
    "#             df[i][j] = x.strip('\\n')\n",
    "#         else:\n",
    "#             x = str(df[i][j])\n",
    "#             df[i][j] = x.strip('\\n')\n",
    "\n",
    "# # Converting the dataframe in csv file\n",
    "\n",
    "# with open('1.csv', 'a') as csvfile:\n",
    "#     df.to_csv(csvfile, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing the table in a CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tt in f_tables:\n",
    "    records = []\n",
    "    for tr in tt.find_all('tr'):\n",
    "        rowString=[]\n",
    "        for td in tr.findAll('td'):\n",
    "            p = td.find_all('p')\n",
    "            if len(p)>0:\n",
    "                for ps in p:\n",
    "                    ps_text = ps.get_text().replace(\"\\n\",\" \") \n",
    "                    ps_text = ps_text.replace(\"\\xa0\",\"\")                 \n",
    "                    rowString.append(ps_text)\n",
    "            else:\n",
    "                td_text=td.get_text().replace(\"\\n\",\" \")\n",
    "                td_text = td_text.replace(\"\\xa0\",\"\")\n",
    "                rowString.append(td_text)\n",
    "        records.append(rowString)        \n",
    "    with open((str(f_tables.index(tt)+1)+'_'+str(cik)+'.csv'), 'w')as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a =(str(f_tables.index(tt)+1)+'_'+str(cik)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    bucket = conn.create_bucket(AWS_ACCESS_KEY_ID.lower()+str(st).replace(\" \", \"\").replace(\"-\", \"\").replace(\":\",\"\").replace(\".\",\"\"), location=location=s3.connection.Location.DEFAULT)\n",
    "    #zipfile = 'Problem1.zip'\n",
    "    logging.info(\"created bucket\")\n",
    "    k = Key(bucket)\n",
    "    k.key = 'Assign1Problem1'\n",
    "    k.set_contents_from_filename(zipfile)\n",
    "    logging.info(\"Have uploaded to AWS S3 properly\")\n",
    "except:\n",
    "    logging.info(\"Something went wrong. Check the amazon keys\")\n",
    "    print(\"vaildate amazon keys\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
